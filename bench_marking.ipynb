{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1DKKLhKD6yQp2QD4wIvZTEvvFTknNS2WE","authorship_tag":"ABX9TyNJCcO9S9qZgvr0Pi3ed0Uj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":74,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UzPkXdlp2Zdo","executionInfo":{"status":"ok","timestamp":1747356385340,"user_tz":180,"elapsed":1299,"user":{"displayName":"Uilmar Vasconcelos da Silva","userId":"03776061601907021366"}},"outputId":"a29c0888-5c2c-48e9-d272-bbbd4e955a60"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["#!git clone https://github.com/uestudante/Bressay.git  ## to acess the data set.\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import requests\n","import simplejson\n","import base64\n","import os\n","from pathlib import Path"],"metadata":{"id":"XeEO6jk7fi1Z","executionInfo":{"status":"ok","timestamp":1747356385345,"user_tz":180,"elapsed":4,"user":{"displayName":"Uilmar Vasconcelos da Silva","userId":"03776061601907021366"}}},"execution_count":75,"outputs":[]},{"cell_type":"markdown","source":["MAKE DIRECTORIES"],"metadata":{"id":"WcOuaAGHko0A"}},{"cell_type":"markdown","source":[],"metadata":{"id":"1thKKx1xBz8h"}},{"cell_type":"code","source":["\n","# os.makedirs('/content/drive', exist_ok=True)\n","\n","models = ['openai/gpt-4o-mini', 'anthropic/claude-3.7-sonnet', 'google/gemini-2.0-flash-001',\n","       'google/gemini-2.5-flash-preview', 'google/gemini-2.5-pro-preview', 'deepseek/deepseek-chat-v3-0324:free',\n","        'deepseek/deepseek-chat-v3-0324', 'google/gemini-2.5-flash-preview:thinking',\n","        'anthropic/claude-3.7-sonnet:thinking', 'openai/gpt-4.1']\n","\n","# diretorios = []\n","\n","#for model in models:\n","#    model = model.replace('/', '-')\n","#    path = os.path.join('/content/Bressay/resultados', model)\n","#    diretorios.append(path)\n","#    os.makedirs(path, exist_ok=True)\n","\n","\n","#partial_path_model = []     ## caminho para guardar resultado de cada modelo\n","\n","#models = ['anthropic/claude-3.7-sonnet'] ##modelos para pesquisa\n","\n","#for model in models:\n","#    model = model.replace('/', '-')\n","#    partial_path_model.append(model)\n","\n","#print(partial_path_model)"],"metadata":{"id":"1VAxmHJSZjE4","executionInfo":{"status":"ok","timestamp":1747356509172,"user_tz":180,"elapsed":7,"user":{"displayName":"Uilmar Vasconcelos da Silva","userId":"03776061601907021366"}}},"execution_count":85,"outputs":[]},{"cell_type":"code","source":["data_set = os.listdir('/content/drive/MyDrive/projeto-correcao-provas/.bressay/data/pages')\n","#print(data_set)\n","\n","output_file_path = '/content/drive/MyDrive/projeto-correcao-provas/.bressay/sets/benchmarking.txt'\n","\n","output_directory = os.path.dirname(output_file_path)\n","os.makedirs(output_directory, exist_ok=True)\n","print(f\"Verificando/criando diretório: {output_directory}\")\n","\n","\n","# Salva as strings no arquivo\n","try:\n","    with open(output_file_path, 'w', encoding='utf-8') as f:\n","        for item in data_set:\n","            f.write(f\"{item}\\n\")\n","    print(f\"Strings salvas com sucesso em '{output_file_path}'\")\n","\n","except Exception as e:\n","    print(f\"Ocorreu um erro ao salvar o arquivo: {e}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VFVZ2oLYRQx9","executionInfo":{"status":"ok","timestamp":1747356385396,"user_tz":180,"elapsed":46,"user":{"displayName":"Uilmar Vasconcelos da Silva","userId":"03776061601907021366"}},"outputId":"3f63379c-a658-416c-8127-842ccb04475c"},"execution_count":77,"outputs":[{"output_type":"stream","name":"stdout","text":["Verificando/criando diretório: /content/drive/MyDrive/projeto-correcao-provas/.bressay/sets\n","Strings salvas com sucesso em '/content/drive/MyDrive/projeto-correcao-provas/.bressay/sets/benchmarking.txt'\n"]}]},{"cell_type":"code","source":["## Using openrouter to benchmarking\n","\n","def encode_image_to_base64(image_path):\n","    with open(image_path, \"rb\") as image_file:\n","        return base64.b64encode(image_file.read()).decode('utf-8')\n","\n","\n","def openrouter_request(image_path, model):\n","    url = \"https://openrouter.ai/api/v1/chat/completions\"\n","\n","    headers = {\n","        \"Authorization\": f\"Bearer {'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'}\",\n","        \"Content-Type\": \"application/json\"\n","    }\n","\n","\n","    base64_image = encode_image_to_base64(image_path)\n","    data_url = f\"data:image/png;base64,{base64_image}\"\n","\n","    messages = [\n","        {\n","            \"role\": \"user\",\n","            \"content\": [\n","                {\n","                    \"type\": \"text\",\n","                    \"text\": \"Only Transcribe into Brazilian Portuguese\"\n","                },\n","                {\n","                    \"type\": \"image_url\",\n","                    \"image_url\": {\n","                        \"url\": data_url\n","                    }\n","                }\n","            ]\n","        }\n","    ]\n","\n","    payload = {\n","        \"model\": model,\n","        \"messages\": messages\n","    }\n","\n","    response = requests.post(url, headers=headers, json=payload)\n","    #print(response.json())\n","\n","\n","    text_json = response.json()\n","    text_content = text_json['choices'][0]['message']['content']\n","    #print(text_content)\n","\n","    return text_content\n","\n"],"metadata":{"id":"JbMrXZqj4Ddc","executionInfo":{"status":"ok","timestamp":1747356476373,"user_tz":180,"elapsed":40,"user":{"displayName":"Uilmar Vasconcelos da Silva","userId":"03776061601907021366"}}},"execution_count":84,"outputs":[]},{"cell_type":"code","source":["def benchmarking(image_path, model):\n","    result = openrouter_request(image_path, model)\n","    #result = ''\n","    model = model.replace('/', '-')\n","    image_name = os.path.basename(image_path)[:-4]\n","    path = os.path.join('/content/drive/MyDrive/projeto-correcao-provas/benchmarking', model)\n","\n","\n","    with open(f'{path}_{image_name}.txt', 'w', encoding='utf-8') as file:\n","        file.write(result)\n"],"metadata":{"id":"npLZ7yGDJfFI","executionInfo":{"status":"ok","timestamp":1747356385428,"user_tz":180,"elapsed":9,"user":{"displayName":"Uilmar Vasconcelos da Silva","userId":"03776061601907021366"}}},"execution_count":79,"outputs":[]},{"cell_type":"code","source":["##\n","num_lines_to_read = 1\n","arquivos_test = []\n","\n","with open(r'/content/drive/MyDrive/projeto-correcao-provas/.bressay/sets/benchmarking.txt', 'r') as file:\n","  for i in range(num_lines_to_read):\n","      arquivo = file.readline()\n","      if not arquivo:\n","        break\n","      arquivos_test.append(arquivo.strip())\n","\n"],"metadata":{"id":"fIZWy9_P3Tjg","executionInfo":{"status":"ok","timestamp":1747356385437,"user_tz":180,"elapsed":2,"user":{"displayName":"Uilmar Vasconcelos da Silva","userId":"03776061601907021366"}}},"execution_count":80,"outputs":[]},{"cell_type":"code","source":["data_directory = r'/content/drive/MyDrive/projeto-correcao-provas/.bressay/data/pages'\n","\n","arquivos_data = []\n","\n","for dir_name in arquivos_test:\n","    full_path = os.path.join(data_directory, dir_name, dir_name) + '.png'\n","    arquivos_data.append(full_path)\n","\n"],"metadata":{"id":"ITkb2WdsBuvR","executionInfo":{"status":"ok","timestamp":1747356385451,"user_tz":180,"elapsed":11,"user":{"displayName":"Uilmar Vasconcelos da Silva","userId":"03776061601907021366"}}},"execution_count":81,"outputs":[]},{"cell_type":"code","source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.metrics.pairwise import cosine_similarity\n","import os\n","\n","# Diretório onde seus arquivos TXT (exceto o gabarito) estão localizados\n","diretorio_textos = '/content/drive/MyDrive/projeto-correcao-provas/benchmarking'\n","\n","# Caminho completo para o arquivo do gabarito\n","# Substitua 'nome_do_arquivo_gabarito.txt' pelo nome real do seu arquivo gabarito\n","caminho_gabarito = '/content/drive/MyDrive/projeto-correcao-provas/benchmarking/gabarito.txt'\n","\n","# Conteúdo do gabarito\n","conteudo_gabarito = \"\"\n","try:\n","    with open(caminho_gabarito, 'r', encoding='utf-8') as f:\n","        conteudo_gabarito = f.read()\n","except FileNotFoundError:\n","    print(f\"Erro: Arquivo de gabarito não encontrado em '{caminho_gabarito}'\")\n","    exit() # Sai do script se o gabarito não for encontrado\n","except Exception as e:\n","    print(f\"Erro ao ler o arquivo de gabarito '{caminho_gabarito}': {e}\")\n","    exit()\n","\n","\n","# Lista para armazenar o conteúdo dos outros textos\n","textos_para_comparar = []\n","# Lista para armazenar os nomes dos arquivos (para referência na saída)\n","nomes_arquivos_para_comparar = []\n","\n","# Percorre todos os arquivos no diretório, exceto o gabarito\n","for nome_arquivo in os.listdir(diretorio_textos):\n","    caminho_completo = os.path.join(diretorio_textos, nome_arquivo)\n","    # Verifica se o arquivo termina com .txt e NÃO é o arquivo do gabarito\n","    if nome_arquivo.endswith('.txt') and caminho_completo != caminho_gabarito:\n","        try:\n","            # Abre e lê o conteúdo do arquivo\n","            with open(caminho_completo, 'r', encoding='utf-8') as f:\n","                conteudo = f.read()\n","                textos_para_comparar.append(conteudo)\n","                nomes_arquivos_para_comparar.append(nome_arquivo)\n","        except Exception as e:\n","            print(f\"Erro ao ler o arquivo {nome_arquivo}: {e}\")\n","\n","\n","# Verifica se há textos para comparar\n","if not textos_para_comparar:\n","    print(\"Nenhum arquivo .txt encontrado para comparação no diretório especificado (excluindo o gabarito).\")\n","else:\n","    # Lista de stop words em português (a mesma lista do exemplo anterior)\n","    stop_words_portugues = [\n","        'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z',\n","        'de', 'a', 'o', 'que', 'e', 'é', 'do', 'da', 'em', 'um', 'para', 'com', 'não', 'uma', 'os', 'as', 'dos', 'das', 'pelo', 'pela', 'pelos', 'pelas',\n","        'até', 'mais', 'como', 'ao', 'aos', 'à', 'às', 'outro', 'outra', 'outros', 'outras', 'este', 'esta', 'estes', 'estas', 'esse', 'essa', 'esses',\n","        'essas', 'aquele', 'aquela', 'aqueles', 'aquelas', 'isto', 'isso', 'aquilo', 'ele', 'ela', 'eles', 'elas', 'se', 'ou', 'quando', 'muito', 'qual',\n","        'quais', 'nos', 'nas', 'no', 'na', 'dele', 'dela', 'deles', 'delas', 'meu', 'minha', 'meus', 'minhas', 'teu', 'tua', 'teus', 'tuas', 'seu', 'sua',\n","        'seus', 'suas', 'nosso', 'nossa', 'nossos', 'nossas', 'vosso', 'vossa', 'vossos', 'vossas', 'por', 'desde', 'sem', 'entre', 'durante', 'perante',\n","        'após', 'sob', 'sobre', 'trás', 'àquele', 'àquela', 'àqueles', 'àquelas', 'desse', 'dessa', 'desses', 'dessas', 'deste', 'desta', 'destes',\n","        'destas', 'àquele', 'àquela', 'àqueles', 'àquelas', 'isso', 'isto', 'aquilo', 'tu', 'vós', 'lhes', 'me', 'te', 'lhe', 'nos', 'vos', 'lhes',\n","        'quem', 'onde', 'porque', 'que', 'talvez', 'assim', 'pois', 'logo', 'portanto', 'entretanto', 'contudo', 'todavia', 'ora', 'já', 'agora',\n","        'ainda', 'depois', 'antes', 'durante', 'enquanto', 'quando', 'se', 'senão', 'embora', 'conforme', 'segundo', 'desde', 'para', 'por', 'perante',\n","        'após', 'sob', 'sobre', 'trás', 'com', 'sem', 'de', 'em', 'entre', 'até', 'desde', 'ante', 'após', 'com', 'contra', 'de', 'desde', 'em',\n","        'entre', 'para', 'perante', 'por', 'sem', 'sob', 'sobre', 'trás', 'a', 'o', 'as', 'os', 'um', 'uma', 'uns', 'umas'\n","    ]\n","\n","    # Inicializa o vetorizador TF-IDF com stop words em português\n","    vectorizer = TfidfVectorizer(stop_words=stop_words_portugues)\n","\n","    # Cria uma lista contendo o gabarito e todos os outros textos\n","    todos_os_textos = [conteudo_gabarito] + textos_para_comparar\n","\n","    # Transforma todos os textos em vetores TF-IDF\n","    vetores_tfidf = vectorizer.fit_transform(todos_os_textos)\n","\n","    # O primeiro vetor (índice 0) corresponde ao gabarito\n","    vetor_gabarito = vetores_tfidf[0]\n","\n","    # Os vetores restantes correspondem aos textos para comparar\n","    vetores_para_comparar = vetores_tfidf[1:]\n","\n","    # Calcula a similaridade de cosseno entre o vetor do gabarito e os outros vetores\n","    similaridades = cosine_similarity(vetor_gabarito, vetores_para_comparar)\n","\n","    # Exibe os resultados\n","    print(f\"Similaridade do Gabarito ('{os.path.basename(caminho_gabarito)}') com outros arquivos:\")\n","    # A matriz de similaridade terá uma linha e o número de colunas igual ao número de textos comparados\n","    for i in range(len(nomes_arquivos_para_comparar)):\n","        # similaridades[0][i] acessa a similaridade entre o gabarito (primeira linha) e o i-ésimo texto para comparar (coluna i)\n","        print(f\"- Arquivo '{nomes_arquivos_para_comparar[i]}': {similaridades[0][i]:.2f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vqACxapvsXAU","executionInfo":{"status":"ok","timestamp":1747359470736,"user_tz":180,"elapsed":1787,"user":{"displayName":"Uilmar Vasconcelos da Silva","userId":"03776061601907021366"}},"outputId":"3ac3fad5-5df8-4651-a5c8-b5542cba2019"},"execution_count":87,"outputs":[{"output_type":"stream","name":"stdout","text":["Similaridade do Gabarito ('gabarito.txt') com outros arquivos:\n","- Arquivo 'anthropic-claude-3.7-sonnet_7611-067.txt': 0.78\n","- Arquivo 'openai-gpt-4o-mini_7611-067.txt': 0.27\n","- Arquivo 'google-gemini-2.0-flash-001_7611-067.txt': 0.99\n","- Arquivo 'google-gemini-2.5-flash-preview_7611-067.txt': 0.76\n","- Arquivo 'google-gemini-2.5-pro-preview_7611-067.txt': 0.93\n","- Arquivo 'deepseek-deepseek-chat-v3-0324:free_7611-067.txt': 0.00\n","- Arquivo 'deepseek-deepseek-chat-v3-0324_7611-067.txt': 0.02\n","- Arquivo 'google-gemini-2.5-flash-preview:thinking_7611-067.txt': 0.78\n","- Arquivo 'anthropic-claude-3.7-sonnet:thinking_7611-067.txt': 0.77\n","- Arquivo 'openai-gpt-4.1_7611-067.txt': 0.44\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"5xTb8DyQl7nP"},"execution_count":null,"outputs":[]}]}