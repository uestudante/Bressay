{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1299,
     "status": "ok",
     "timestamp": 1747356385340,
     "user": {
      "displayName": "Uilmar Vasconcelos da Silva",
      "userId": "03776061601907021366"
     },
     "user_tz": 180
    },
    "id": "UzPkXdlp2Zdo",
    "outputId": "a29c0888-5c2c-48e9-d272-bbbd4e955a60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "#!git clone https://github.com/uestudante/Bressay.git  ## to acess the data set.\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1747356385345,
     "user": {
      "displayName": "Uilmar Vasconcelos da Silva",
      "userId": "03776061601907021366"
     },
     "user_tz": 180
    },
    "id": "XeEO6jk7fi1Z"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import simplejson\n",
    "import base64\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WcOuaAGHko0A"
   },
   "source": [
    "MAKE DIRECTORIES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1thKKx1xBz8h"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1747356509172,
     "user": {
      "displayName": "Uilmar Vasconcelos da Silva",
      "userId": "03776061601907021366"
     },
     "user_tz": 180
    },
    "id": "1VAxmHJSZjE4"
   },
   "outputs": [],
   "source": [
    "\n",
    "# os.makedirs('/content/drive', exist_ok=True)\n",
    "\n",
    "models = ['openai/gpt-4o-mini', 'anthropic/claude-3.7-sonnet', 'google/gemini-2.0-flash-001',\n",
    "       'google/gemini-2.5-flash-preview', 'google/gemini-2.5-pro-preview', 'deepseek/deepseek-chat-v3-0324:free',\n",
    "        'deepseek/deepseek-chat-v3-0324', 'google/gemini-2.5-flash-preview:thinking',\n",
    "        'anthropic/claude-3.7-sonnet:thinking', 'openai/gpt-4.1']\n",
    "\n",
    "# diretorios = []\n",
    "\n",
    "#for model in models:\n",
    "#    model = model.replace('/', '-')\n",
    "#    path = os.path.join('/content/Bressay/resultados', model)\n",
    "#    diretorios.append(path)\n",
    "#    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "\n",
    "#partial_path_model = []     ## caminho para guardar resultado de cada modelo\n",
    "\n",
    "#models = ['anthropic/claude-3.7-sonnet'] ##modelos para pesquisa\n",
    "\n",
    "#for model in models:\n",
    "#    model = model.replace('/', '-')\n",
    "#    partial_path_model.append(model)\n",
    "\n",
    "#print(partial_path_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 46,
     "status": "ok",
     "timestamp": 1747356385396,
     "user": {
      "displayName": "Uilmar Vasconcelos da Silva",
      "userId": "03776061601907021366"
     },
     "user_tz": 180
    },
    "id": "VFVZ2oLYRQx9",
    "outputId": "3f63379c-a658-416c-8127-842ccb04475c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verificando/criando diretório: /content/drive/MyDrive/projeto-correcao-provas/.bressay/sets\n",
      "Strings salvas com sucesso em '/content/drive/MyDrive/projeto-correcao-provas/.bressay/sets/benchmarking.txt'\n"
     ]
    }
   ],
   "source": [
    "data_set = os.listdir('/content/drive/MyDrive/projeto-correcao-provas/.bressay/data/pages')\n",
    "#print(data_set)\n",
    "\n",
    "output_file_path = '/content/drive/MyDrive/projeto-correcao-provas/.bressay/sets/benchmarking.txt'\n",
    "\n",
    "output_directory = os.path.dirname(output_file_path)\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "print(f\"Verificando/criando diretório: {output_directory}\")\n",
    "\n",
    "\n",
    "# Salva as strings no arquivo\n",
    "try:\n",
    "    with open(output_file_path, 'w', encoding='utf-8') as f:\n",
    "        for item in data_set:\n",
    "            f.write(f\"{item}\\n\")\n",
    "    print(f\"Strings salvas com sucesso em '{output_file_path}'\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Ocorreu um erro ao salvar o arquivo: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 40,
     "status": "ok",
     "timestamp": 1747356476373,
     "user": {
      "displayName": "Uilmar Vasconcelos da Silva",
      "userId": "03776061601907021366"
     },
     "user_tz": 180
    },
    "id": "JbMrXZqj4Ddc"
   },
   "outputs": [],
   "source": [
    "## Using openrouter to benchmarking\n",
    "\n",
    "def encode_image_to_base64(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "\n",
    "def openrouter_request(image_path, model):\n",
    "    url = \"https://openrouter.ai/api/v1/chat/completions\"\n",
    "\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {'TOKEN'}\",  ## token para acesso API\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "\n",
    "    base64_image = encode_image_to_base64(image_path)\n",
    "    data_url = f\"data:image/png;base64,{base64_image}\"\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"Only Transcribe into Brazilian Portuguese\"\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": data_url\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"messages\": messages\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, headers=headers, json=payload)\n",
    "    #print(response.json())\n",
    "\n",
    "\n",
    "    text_json = response.json()\n",
    "    text_content = text_json['choices'][0]['message']['content']\n",
    "    #print(text_content)\n",
    "\n",
    "    return text_content\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1747356385428,
     "user": {
      "displayName": "Uilmar Vasconcelos da Silva",
      "userId": "03776061601907021366"
     },
     "user_tz": 180
    },
    "id": "npLZ7yGDJfFI"
   },
   "outputs": [],
   "source": [
    "def benchmarking(image_path, model):\n",
    "    result = openrouter_request(image_path, model)\n",
    "    #result = ''\n",
    "    model = model.replace('/', '-')\n",
    "    image_name = os.path.basename(image_path)[:-4]\n",
    "    path = os.path.join('/content/drive/MyDrive/projeto-correcao-provas/benchmarking', model)\n",
    "\n",
    "\n",
    "    with open(f'{path}_{image_name}.txt', 'w', encoding='utf-8') as file:\n",
    "        file.write(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1747356385437,
     "user": {
      "displayName": "Uilmar Vasconcelos da Silva",
      "userId": "03776061601907021366"
     },
     "user_tz": 180
    },
    "id": "fIZWy9_P3Tjg"
   },
   "outputs": [],
   "source": [
    "##\n",
    "num_lines_to_read = 1\n",
    "arquivos_test = []\n",
    "\n",
    "with open(r'/content/drive/MyDrive/projeto-correcao-provas/.bressay/sets/benchmarking.txt', 'r') as file:\n",
    "  for i in range(num_lines_to_read):\n",
    "      arquivo = file.readline()\n",
    "      if not arquivo:\n",
    "        break\n",
    "      arquivos_test.append(arquivo.strip())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1747356385451,
     "user": {
      "displayName": "Uilmar Vasconcelos da Silva",
      "userId": "03776061601907021366"
     },
     "user_tz": 180
    },
    "id": "ITkb2WdsBuvR"
   },
   "outputs": [],
   "source": [
    "data_directory = r'/content/drive/MyDrive/projeto-correcao-provas/.bressay/data/pages'\n",
    "\n",
    "arquivos_data = []\n",
    "\n",
    "for dir_name in arquivos_test:\n",
    "    full_path = os.path.join(data_directory, dir_name, dir_name) + '.png'\n",
    "    arquivos_data.append(full_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1787,
     "status": "ok",
     "timestamp": 1747359470736,
     "user": {
      "displayName": "Uilmar Vasconcelos da Silva",
      "userId": "03776061601907021366"
     },
     "user_tz": 180
    },
    "id": "vqACxapvsXAU",
    "outputId": "3ac3fad5-5df8-4651-a5c8-b5542cba2019"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similaridade do Gabarito ('gabarito.txt') com outros arquivos:\n",
      "- Arquivo 'anthropic-claude-3.7-sonnet_7611-067.txt': 0.78\n",
      "- Arquivo 'openai-gpt-4o-mini_7611-067.txt': 0.27\n",
      "- Arquivo 'google-gemini-2.0-flash-001_7611-067.txt': 0.99\n",
      "- Arquivo 'google-gemini-2.5-flash-preview_7611-067.txt': 0.76\n",
      "- Arquivo 'google-gemini-2.5-pro-preview_7611-067.txt': 0.93\n",
      "- Arquivo 'deepseek-deepseek-chat-v3-0324:free_7611-067.txt': 0.00\n",
      "- Arquivo 'deepseek-deepseek-chat-v3-0324_7611-067.txt': 0.02\n",
      "- Arquivo 'google-gemini-2.5-flash-preview:thinking_7611-067.txt': 0.78\n",
      "- Arquivo 'anthropic-claude-3.7-sonnet:thinking_7611-067.txt': 0.77\n",
      "- Arquivo 'openai-gpt-4.1_7611-067.txt': 0.44\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import os\n",
    "\n",
    "# Diretório onde seus arquivos TXT (exceto o gabarito) estão localizados\n",
    "diretorio_textos = '/content/drive/MyDrive/projeto-correcao-provas/benchmarking'\n",
    "\n",
    "# Caminho completo para o arquivo do gabarito\n",
    "# Substitua 'nome_do_arquivo_gabarito.txt' pelo nome real do seu arquivo gabarito\n",
    "caminho_gabarito = '/content/drive/MyDrive/projeto-correcao-provas/benchmarking/gabarito.txt'\n",
    "\n",
    "# Conteúdo do gabarito\n",
    "conteudo_gabarito = \"\"\n",
    "try:\n",
    "    with open(caminho_gabarito, 'r', encoding='utf-8') as f:\n",
    "        conteudo_gabarito = f.read()\n",
    "except FileNotFoundError:\n",
    "    print(f\"Erro: Arquivo de gabarito não encontrado em '{caminho_gabarito}'\")\n",
    "    exit() # Sai do script se o gabarito não for encontrado\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao ler o arquivo de gabarito '{caminho_gabarito}': {e}\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "# Lista para armazenar o conteúdo dos outros textos\n",
    "textos_para_comparar = []\n",
    "# Lista para armazenar os nomes dos arquivos (para referência na saída)\n",
    "nomes_arquivos_para_comparar = []\n",
    "\n",
    "# Percorre todos os arquivos no diretório, exceto o gabarito\n",
    "for nome_arquivo in os.listdir(diretorio_textos):\n",
    "    caminho_completo = os.path.join(diretorio_textos, nome_arquivo)\n",
    "    # Verifica se o arquivo termina com .txt e NÃO é o arquivo do gabarito\n",
    "    if nome_arquivo.endswith('.txt') and caminho_completo != caminho_gabarito:\n",
    "        try:\n",
    "            # Abre e lê o conteúdo do arquivo\n",
    "            with open(caminho_completo, 'r', encoding='utf-8') as f:\n",
    "                conteudo = f.read()\n",
    "                textos_para_comparar.append(conteudo)\n",
    "                nomes_arquivos_para_comparar.append(nome_arquivo)\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao ler o arquivo {nome_arquivo}: {e}\")\n",
    "\n",
    "\n",
    "# Verifica se há textos para comparar\n",
    "if not textos_para_comparar:\n",
    "    print(\"Nenhum arquivo .txt encontrado para comparação no diretório especificado (excluindo o gabarito).\")\n",
    "else:\n",
    "    # Lista de stop words em português (a mesma lista do exemplo anterior)\n",
    "    stop_words_portugues = [\n",
    "        'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z',\n",
    "        'de', 'a', 'o', 'que', 'e', 'é', 'do', 'da', 'em', 'um', 'para', 'com', 'não', 'uma', 'os', 'as', 'dos', 'das', 'pelo', 'pela', 'pelos', 'pelas',\n",
    "        'até', 'mais', 'como', 'ao', 'aos', 'à', 'às', 'outro', 'outra', 'outros', 'outras', 'este', 'esta', 'estes', 'estas', 'esse', 'essa', 'esses',\n",
    "        'essas', 'aquele', 'aquela', 'aqueles', 'aquelas', 'isto', 'isso', 'aquilo', 'ele', 'ela', 'eles', 'elas', 'se', 'ou', 'quando', 'muito', 'qual',\n",
    "        'quais', 'nos', 'nas', 'no', 'na', 'dele', 'dela', 'deles', 'delas', 'meu', 'minha', 'meus', 'minhas', 'teu', 'tua', 'teus', 'tuas', 'seu', 'sua',\n",
    "        'seus', 'suas', 'nosso', 'nossa', 'nossos', 'nossas', 'vosso', 'vossa', 'vossos', 'vossas', 'por', 'desde', 'sem', 'entre', 'durante', 'perante',\n",
    "        'após', 'sob', 'sobre', 'trás', 'àquele', 'àquela', 'àqueles', 'àquelas', 'desse', 'dessa', 'desses', 'dessas', 'deste', 'desta', 'destes',\n",
    "        'destas', 'àquele', 'àquela', 'àqueles', 'àquelas', 'isso', 'isto', 'aquilo', 'tu', 'vós', 'lhes', 'me', 'te', 'lhe', 'nos', 'vos', 'lhes',\n",
    "        'quem', 'onde', 'porque', 'que', 'talvez', 'assim', 'pois', 'logo', 'portanto', 'entretanto', 'contudo', 'todavia', 'ora', 'já', 'agora',\n",
    "        'ainda', 'depois', 'antes', 'durante', 'enquanto', 'quando', 'se', 'senão', 'embora', 'conforme', 'segundo', 'desde', 'para', 'por', 'perante',\n",
    "        'após', 'sob', 'sobre', 'trás', 'com', 'sem', 'de', 'em', 'entre', 'até', 'desde', 'ante', 'após', 'com', 'contra', 'de', 'desde', 'em',\n",
    "        'entre', 'para', 'perante', 'por', 'sem', 'sob', 'sobre', 'trás', 'a', 'o', 'as', 'os', 'um', 'uma', 'uns', 'umas'\n",
    "    ]\n",
    "\n",
    "    # Inicializa o vetorizador TF-IDF com stop words em português\n",
    "    vectorizer = TfidfVectorizer(stop_words=stop_words_portugues)\n",
    "\n",
    "    # Cria uma lista contendo o gabarito e todos os outros textos\n",
    "    todos_os_textos = [conteudo_gabarito] + textos_para_comparar\n",
    "\n",
    "    # Transforma todos os textos em vetores TF-IDF\n",
    "    vetores_tfidf = vectorizer.fit_transform(todos_os_textos)\n",
    "\n",
    "    # O primeiro vetor (índice 0) corresponde ao gabarito\n",
    "    vetor_gabarito = vetores_tfidf[0]\n",
    "\n",
    "    # Os vetores restantes correspondem aos textos para comparar\n",
    "    vetores_para_comparar = vetores_tfidf[1:]\n",
    "\n",
    "    # Calcula a similaridade de cosseno entre o vetor do gabarito e os outros vetores\n",
    "    similaridades = cosine_similarity(vetor_gabarito, vetores_para_comparar)\n",
    "\n",
    "    # Exibe os resultados\n",
    "    print(f\"Similaridade do Gabarito ('{os.path.basename(caminho_gabarito)}') com outros arquivos:\")\n",
    "    # A matriz de similaridade terá uma linha e o número de colunas igual ao número de textos comparados\n",
    "    for i in range(len(nomes_arquivos_para_comparar)):\n",
    "        # similaridades[0][i] acessa a similaridade entre o gabarito (primeira linha) e o i-ésimo texto para comparar (coluna i)\n",
    "        print(f\"- Arquivo '{nomes_arquivos_para_comparar[i]}': {similaridades[0][i]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5xTb8DyQl7nP"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNJCcO9S9qZgvr0Pi3ed0Uj",
   "mount_file_id": "1DKKLhKD6yQp2QD4wIvZTEvvFTknNS2WE",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
